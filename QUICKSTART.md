# Real Estate Data Pipeline - Quick Start Guide

## ğŸš€ Single Entry Point

All agents are now accessible through one main program:

```powershell
python main.py
```

## ğŸ“‹ Menu Options

### 1. ğŸ“¥ Fetch Data from GCS
Download files from Google Cloud Storage bucket to local storage.

### 2. ğŸ”„ Normalize Files
Convert CSV/Excel files to BigQuery-ready format:
- **Single file**: Normalize one specific file
- **Batch process**: Normalize all files in `downloads/multi_agent_workflow/`
- **Excel multi-sheet**: Automatically processes all sheets

### 3. â¬†ï¸ Upload to BigQuery
Upload normalized CSV files to BigQuery tables:
- **All files**: Upload everything in `normalized/` folder
- **Single file**: Select specific file to upload

### 4. ğŸ¤– Query with AI
Ask questions in natural language using Vertex AI:
- Converts questions to SQL automatically
- Executes queries on BigQuery
- Returns AI-generated natural language responses

### 5. ğŸš€ Full Pipeline
Run complete workflow automatically:
1. Normalize all files in downloads
2. Upload all to BigQuery

### 6. ğŸ“Š List Files
View available source and normalized files

### 7. âŒ Exit
Close the program

## ğŸ“ Directory Structure

```
d:\RAG\1512\
â”œâ”€â”€ main.py                          # ğŸ‘ˆ START HERE
â”œâ”€â”€ .env                             # Configuration
â”œâ”€â”€ downloads/
â”‚   â””â”€â”€ multi_agent_workflow/           # Raw data files
â”œâ”€â”€ normalized/                      # Processed CSV files
â””â”€â”€ agents/
    â”œâ”€â”€ LocalNormalizerAgent.py     # File normalization
    â”œâ”€â”€ BigQueryAgent.py            # BigQuery uploads
    â”œâ”€â”€ VertexAIQueryAgent.py       # AI queries
    â””â”€â”€ fetch_data.py               # GCS downloads
```

## âš™ï¸ Configuration (.env file)

Required environment variables:

```env
BQ_PROJECT_ID=your-gcp-project-id
BQ_DATASET_ID=your-bigquery-dataset
GOOGLE_CLOUD_PROJECT=your-gcp-project-id
GOOGLE_CLOUD_LOCATION=us-central1
GOOGLE_APPLICATION_CREDENTIALS=path/to/service-account.json
```

## ğŸ¯ Quick Workflow

### First Time Setup:
```powershell
# 1. Install dependencies
pip install -r requirements.txt
pip install python-dotenv openpyxl

# 2. Configure .env file
# Add your GCP credentials

# 3. Run main program
python main.py
```

### Typical Usage:
1. Run `python main.py`
2. Choose option **5** (Full Pipeline) to process all files
3. Choose option **4** to start querying your data with AI

### Example AI Queries:
- "What are the top 10 states by flood zone policies?"
- "Show me average SAFMR rates by ZIP code"
- "Which states have the most real estate listings?"
- "What are the total financial losses by state?"

## ğŸ› ï¸ Individual Agent Usage

You can still run agents directly if needed:

```powershell
# Normalize a single file
python LocalNormalizerAgent.py path/to/file.xlsx normalized/

# Query with AI
python VertexAIQueryAgent.py "your natural language question"
```

## ğŸ“Š Supported File Types

- **CSV** (.csv)
- **Excel** (.xlsx, .xls) - all sheets processed automatically
- **Large files** - optimized for files with millions of rows

## âœ¨ Features

- âœ… Automatic schema detection
- âœ… Multi-sheet Excel support
- âœ… Relationship detection between sheets
- âœ… BigQuery data type optimization
- âœ… Natural language querying with AI
- âœ… Error handling and validation
- âœ… Progress tracking

## ğŸ”§ Troubleshooting

**"Missing .env file"**
- Create `.env` file with required variables

**"File not found"**
- Ensure files are in `downloads/multi_agent_workflow/`

**"BigQuery authentication error"**
- Set `GOOGLE_APPLICATION_CREDENTIALS` in .env
- Or run: `gcloud auth application-default login`

**"openpyxl not found"**
- Run: `pip install openpyxl`

## ğŸ“ Support

For issues or questions, check the error messages in the terminal output.
